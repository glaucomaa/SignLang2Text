## SLTTransformerModel

SLTTransformerModel — это модель на основе Transformer для задачи перевода жестового языка (Sign Language Translation). Она принимает на вход видеопризнаки и возвращает логиты над словарём токенов, соответствующие переводу на естественный язык.

### Архитектура

Модель состоит из следующих компонентов:

* input_fc: линейная проекция входных признаков размерности input_dim → d_model
* TransformerEncoder: стек энкодеров с многоуровневым вниманием и позиционным кодированием
* Embedding + PositionalEncoding: кодирование целевых токенов
* TransformerDecoder: стек декодеров
* out_proj: линейный слой, преобразующий выход декодера в логиты над словарём

Позиционное кодирование реализовано вручную через класс PositionalEncoding

### Параметры конфигурации 

| Параметр             | Описание                                            |
| -------------------- | --------------------------------------------------- |
| `input_dim`          | Размерность входных признаков  |
| `vocab_size`         | Размер словаря выходных токенов                     |
| `d_model`            | Размерность скрытых представлений                   |
| `nhead`              | Количество "голов" в механизме multi-head attention |
| `num_encoder_layers` | Число слоёв в энкодере                              |
| `num_decoder_layers` | Число слоёв в декодере                              |
| `dim_feedforward`    | Размер скрытого слоя внутри FFN                     |
| `dropout`            | Dropout-рейт                                        |
| `pad_idx`            | Индекс padding-токена                               |
| `max_len`            | Максимальная длина последовательностей              |

### Входные данные

Метод forward ожидает:

* src_feats: Tensor[B, T_src, input_dim] — входные признаки 
* tgt_tokens: Tensor[B, T_tgt] — токены 
* memory_key_padding_mask : Tensor[B, T_src] — маска  для паддингов

### Выход

* logits: Tensor[B, T_tgt, vocab_size] — логиты по словарю для каждого токена в последовательности цели


### Экспериментальные параметры



Эксперимент  d_model  nhead  encoder_layers  decoder_layers  dim_feedforward  dropout  lr     batch_size  
---------------------------------------------------------------------------------------------------------------
Exp01        256      4      6               3               1024             0.3      3e-4   64           - EM=0.000 | CER=1.99 | WER=1.22 | BLEU=0.5
Exp02        384      4      6               3               1024             0.3      3e-4   64           - EM=0.000 | CER=2.43 | WER=1.86 | BLEU=0.286
Exp03        512      4      6               3               1024             0.3      3e-4   64           - EM=0.000 | CER=2.55 | WER=2.11 | BLEU=0.28
Exp04        384      6      6               4               1024             0.3      3e-4   64           - EM=0.000 | CER=2.31 | WER=1.78 | BLEU=0.3
Exp05        256      8      8               6               1024             0.3      3e-4   64           - EM=0.000 | CER=2.08 | WER=1.27 | BLEU=0.3
Exp06        256      8      6               3               1024             0.3      3e-4   64           -
Exp07        256      4      6               3               1024             0.1      3e-4   64           - 
Exp08        256      4      4               2               1024             0.3      3e-4   32           -
Exp09        384      6      6               3               2048             0.3      2e-4   32           -
Exp10        384      6      6               3               2048             0.3      1e-4   64           -
Exp11        512      8      4               4               2048             0.3      3e-4   32           -





